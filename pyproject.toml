[tool.poetry]
name = "ember-ai"
version = "0.1.0"
description = "Compositional framework for building and orchestrating Compound AI Systems and Networks of Networks (NONs)."
authors = ["Jared Quincy Davis <jaredq@cs.stanford.edu>"]
maintainers = ["Ember Team <team@pyember.org>"]
readme = "README.md"
license = "Apache-2.0"
repository = "https://github.com/pyember/ember"
documentation = "https://ember-ai.readthedocs.io"
homepage = "https://pyember.org"
keywords = ["AI", "LLM", "Networks of Networks", "Machine Learning", "Compound AI", "Orchestration"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "Intended Audience :: Science/Research",
    "License :: OSI Approved :: Apache Software License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.11",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
]
packages = [
    { include = "ember/**/*.py", from = "src" },
]

[tool.poetry.dependencies]
python = ">=3.11,<3.12"
pandas = ">=1.0.0,<2.2.0"
numpy = ">=1.21.0,<1.27.0"

# Core dependencies
pydantic = "2.7.4"
pydantic-core = "2.18.4"
pydantic-settings = "2.3.0"
PyYAML = "6.0.1"
typing_extensions = "4.12.2"

# LLM providers
openai = "1.57.2"
anthropic = "0.40.0"
google-generativeai = ">=0.8.3"
ibm-watsonx-ai = "1.1.25"

# HTTP and async
aiohttp = "3.9.5"
aiosignal = "1.3.1"
httpx = "0.27.0"
requests = "2.32.2"  # Downgraded to satisfy ibm-cos-sdk-core requirements

# Data processing
datasets = "2.20.0"
scikit-learn = "1.6.0"
scipy = "1.13.1"
huggingface-hub = "0.26.5"
pyarrow = "16.1.0"
"pyarrow-hotfix" = "0.6"

# Visualization
matplotlib = "3.9.1"
prettytable = "3.12.0"

# Utilities
tqdm = "4.67.1"
tenacity = "9.0.0"
cachetools = "5.4.0"
dill = "0.3.8"

# Google API dependencies
google-ai-generativelanguage = "^0.6.6"
google-api-core = "2.19.1"
google-api-python-client = "2.139.0"
google-auth = "2.32.0"
google-auth-httplib2 = "0.2.0"
googleapis-common-protos = "1.63.2"

# Additional dependencies
annotated-types = "0.7.0"
anyio = "4.4.0"
attrs = "23.2.0"
certifi = "2024.6.2"
charset-normalizer = "3.3.2"
contourpy = "1.2.1"
cycler = "0.12.1"
distro = "1.9.0"
filelock = "3.15.1"
fonttools = "4.53.1"
frozenlist = "1.4.1"
fsspec = "2024.5.0"
grpcio = "1.65.4"
grpcio-status = "1.62.2"
h11 = "0.14.0"
httpcore = "1.0.5"
httplib2 = "0.22.0"
idna = "3.7"
iniconfig = "2.0.0"
jiter = "0.5.0"
joblib = "1.4.2"
kiwisolver = "1.4.5"
multidict = "6.0.5"
multiprocess = "0.70.16"
packaging = "24.1"
pillow = "10.4.0"
pluggy = "1.5.0"
proto-plus = "1.24.0"
protobuf = "4.25.4"
pyasn1 = "0.6.0"
pyasn1_modules = "0.4.0"
pyparsing = "3.1.2"
python-dateutil = "2.9.0.post0"
pytz = "2024.1"
rsa = "4.9"
setuptools = "75.2.0"
six = "1.16.0"
sniffio = "1.3.1"
threadpoolctl = "3.5.0"
tokenizers = "0.19.1"
tzdata = "2024.1"
uritemplate = "4.1.1"
urllib3 = "1.26.19"  # Downgraded from 2.2.1 to satisfy dependency constraints
wcwidth = "0.2.13"
xxhash = "3.4.1"
yarl = "1.9.4"

[tool.poetry.extras]
all = ["dev", "docs", "optional"]
dev = ["pytest", "parameterized", "jupyterlab", "ipykernel", "pytest-cov", "hypothesis", "mutmut", "tox", "atheris"]
docs = ["sphinx", "sphinx-rtd-theme", "nbsphinx", "myst-parser"]
optional = ["jupyter", "notebook", "matplotlib"]

[tool.poetry.group.dev.dependencies]
# Testing
pytest = "8.3.2"
parameterized = "0.9.0"
pytest-cov = "4.1.0"
hypothesis = "6.99.0"
mutmut = "2.4.4"
tox = "4.11.4"
atheris = "2.3.0"

# Development environment
jupyterlab = "4.0.6"
ipykernel = "6.26.0"
black = "^23.12.0"
isort = "^5.12.0"
mypy = "^1.7.1"
pylint = "^3.0.2"
pre-commit = "^3.5.0"
ruff = "^0.1.6"

[tool.poetry.group.docs]
optional = true

[tool.poetry.group.docs.dependencies]
sphinx = "^7.1.0"
sphinx-rtd-theme = "^1.3.0"
nbsphinx = "^0.9.3"
myst-parser = "^2.0.0"

[tool.pytest.ini_options]
pythonpath = [
    ".",
    "src",
    "tests"
]
testpaths = ["tests"]
python_files = "test_*.py"
python_classes = "Test*"
python_functions = "test_*"
addopts = "--import-mode=importlib --cov=src/ember --cov-report=term --cov-report=html --cov-report=xml"

[tool.coverage.run]
source = ["src/ember"]
omit = ["*/__init__.py", "*/test_*.py", "tests/*"]
branch = true

[tool.coverage.report]
exclude_lines = [
    "pragma: no cover",
    "def __repr__",
    "raise NotImplementedError",
    "if TYPE_CHECKING",
    "pass",
    "\\.\\.\\."
]
fail_under = 90
show_missing = true

[tool.hypothesis]
deadline = 500
max_examples = 100
verbosity = 1
suppress_health_check = ["too_slow"]

[tool.black]
line-length = 88
target-version = ["py311"]
include = '\.pyi?$'

[tool.isort]
profile = "black"
line_length = 88
multi_line_output = 3

[tool.mypy]
python_version = "3.11"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
check_untyped_defs = true
disallow_untyped_decorators = true
no_implicit_optional = true
strict_optional = true

[tool.ruff]
line-length = 88
target-version = "py311"
select = ["E", "F", "B", "I"]
ignore = []

[build-system]
requires = ["poetry-core>=1.5.0"]
build-backend = "poetry.core.masonry.api"

[tool.poetry.plugins."ember.dataset_preppers"]
truthful_qa = "ember.core.utils.data.datasets_registry.truthful_qa:TruthfulQAPrepper"
short_answer = "ember.core.utils.data.datasets_registry.short_answer:ShortAnswerPrepper"
commonsense_qa = "ember.core.utils.data.datasets_registry.commonsense_qa:CommonsenseQAPrepper"
halueval = "ember.core.utils.data.datasets_registry.halueval:HaluEvalPrepper"
mmlu = "ember.core.utils.data.datasets_registry.mmlu:MMLUPrepper"

[tool.setuptools]
package-dir = {"" = "src"}
packages = ["ember"]