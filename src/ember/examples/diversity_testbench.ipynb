{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diversity Testbench\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ember Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: things below this are to install required dependencies (do this in the virtual env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q -e .\n",
    "# %pip install -q google-generativeai==0.7.2\n",
    "\n",
    "# embedding model dependencies\n",
    "# %pip install -q openai\n",
    "\n",
    "# compression ratio dependencies\n",
    "%pip install -q diversity==0.2.0\n",
    "%pip install -q spacy==3.8.4\n",
    "\n",
    "# edit distance\n",
    "%pip install -q python-Levenshtein\n",
    "\n",
    "# ensemble example\n",
    "%pip install -q matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports & dependencies\n",
    "from __future__ import annotations\n",
    "\n",
    "import logging, sys, os, math, re, subprocess\n",
    "from typing import Dict, Any, List, Protocol, TypeVar, Optional, Generic, Callable, Union\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "from diversity import compression_ratio\n",
    "import Levenshtein\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# ember repo loads\n",
    "from ember.core.registry.model.config.settings import initialize_registry\n",
    "from ember.core.registry.model.base.services.model_service import ModelService\n",
    "from ember.core.registry.model.base.schemas.model_info import ModelInfo\n",
    "from ember.core.registry.model.base.schemas.cost import ModelCost, RateLimit\n",
    "from ember.core.registry.model.base.schemas.provider_info import ProviderInfo\n",
    "\n",
    "from ember.core.registry.model import load_model, ChatResponse\n",
    "from ember.core.registry.model.base.services.model_service import ModelService\n",
    "\n",
    "from ember.core.utils.eval.base_evaluator import IEvaluator, EvaluationResult\n",
    "from ember.core.utils.eval.extractors import RegexExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Set global logging level to ERROR\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "os.environ[\"EMBER_LOGGING_LEVEL\"] = \"ERROR\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mounting to root directory of ember"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/ember/jared/ember\n"
     ]
    }
   ],
   "source": [
    "# fixing dependencies if current path is <root>/src/ember/examples/diversity_testbench.ipynb\n",
    "target_dir = 'src/ember/examples'\n",
    "if os.getcwd()[-18:] == target_dir:\n",
    "    os.chdir('../../..')\n",
    "print(os.getcwd())\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/ember/jared/ember\n"
     ]
    }
   ],
   "source": [
    "!echo $PWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1625361117.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mmodel_registry = initialize_ember(config_path=)\u001b[39m\n                                                  ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model_registry = initialize_registry()\n",
    "# model_registry = initialize_ember()\n",
    "llm = ModelService(registry=model_registry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Model Registry checks \n",
    "\n",
    "From the code above, it should auto add models from your config files (which can displayed from printing below), but you can also add your own models as shown below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['openai:gpt-4o-mini-transcribe',\n",
       " 'openai:gpt-4o-audio-preview-2024-12-17',\n",
       " 'openai:dall-e-3',\n",
       " 'openai:dall-e-2',\n",
       " 'openai:gpt-4o-audio-preview-2024-10-01',\n",
       " 'openai:gpt-4o-mini-2024-07-18',\n",
       " 'openai:gpt-4o-realtime-preview-2024-10-01',\n",
       " 'openai:gpt-4o-mini',\n",
       " 'openai:gpt-4o-audio-preview',\n",
       " 'openai:text-embedding-3-large',\n",
       " 'openai:gpt-4',\n",
       " 'openai:gpt-4o-2024-05-13',\n",
       " 'openai:gpt-4o-realtime-preview',\n",
       " 'openai:gpt-4o-mini-audio-preview',\n",
       " 'openai:gpt-3.5-turbo-instruct-0914',\n",
       " 'openai:gpt-4o-mini-search-preview',\n",
       " 'openai:gpt-3.5-turbo-1106',\n",
       " 'openai:gpt-4o-search-preview',\n",
       " 'openai:gpt-4-turbo',\n",
       " 'openai:gpt-4o-realtime-preview-2024-12-17',\n",
       " 'openai:gpt-3.5-turbo-instruct',\n",
       " 'openai:gpt-3.5-turbo',\n",
       " 'openai:gpt-4-turbo-preview',\n",
       " 'openai:gpt-4o-mini-search-preview-2025-03-11',\n",
       " 'openai:gpt-4o-mini-realtime-preview',\n",
       " 'openai:gpt-3.5-turbo-0125',\n",
       " 'openai:gpt-4o-2024-08-06',\n",
       " 'openai:gpt-4-turbo-2024-04-09',\n",
       " 'openai:gpt-3.5-turbo-16k',\n",
       " 'openai:gpt-4o',\n",
       " 'openai:gpt-4o-mini-realtime-preview-2024-12-17',\n",
       " 'openai:gpt-4-1106-preview',\n",
       " 'openai:text-embedding-ada-002',\n",
       " 'openai:gpt-4-0613',\n",
       " 'openai:gpt-4.5-preview',\n",
       " 'openai:gpt-4.5-preview-2025-02-27',\n",
       " 'openai:gpt-4o-search-preview-2025-03-11',\n",
       " 'openai:gpt-4o-2024-11-20',\n",
       " 'openai:gpt-4o-mini-tts',\n",
       " 'openai:gpt-4-0125-preview',\n",
       " 'openai:gpt-4o-transcribe',\n",
       " 'openai:text-embedding-3-small',\n",
       " 'openai:gpt-4o-mini-audio-preview-2024-12-17',\n",
       " 'anthropic:claude-3-sonnet',\n",
       " 'anthropic:claude-3-opus',\n",
       " 'anthropic:claude-3-haiku',\n",
       " 'anthropic:claude-3.5-sonnet',\n",
       " 'anthropic:claude-3.7-sonnet',\n",
       " 'google:models/gemini-1.0-pro-vision-latest',\n",
       " 'google:models/gemini-pro-vision',\n",
       " 'google:models/gemini-1.5-pro-latest',\n",
       " 'google:models/gemini-1.5-pro-001',\n",
       " 'google:models/gemini-1.5-pro-002',\n",
       " 'google:models/gemini-1.5-pro',\n",
       " 'google:models/gemini-1.5-flash-latest',\n",
       " 'google:models/gemini-1.5-flash-001',\n",
       " 'google:models/gemini-1.5-flash-001-tuning',\n",
       " 'google:models/gemini-1.5-flash',\n",
       " 'google:models/gemini-1.5-flash-002',\n",
       " 'google:models/gemini-1.5-flash-8b',\n",
       " 'google:models/gemini-1.5-flash-8b-001',\n",
       " 'google:models/gemini-1.5-flash-8b-latest',\n",
       " 'google:models/gemini-1.5-flash-8b-exp-0827',\n",
       " 'google:models/gemini-1.5-flash-8b-exp-0924',\n",
       " 'google:models/gemini-2.0-flash-exp',\n",
       " 'google:models/gemini-2.0-flash',\n",
       " 'google:models/gemini-2.0-flash-001',\n",
       " 'google:models/gemini-2.0-flash-exp-image-generation',\n",
       " 'google:models/gemini-2.0-flash-lite-001',\n",
       " 'google:models/gemini-2.0-flash-lite',\n",
       " 'google:models/gemini-2.0-flash-lite-preview-02-05',\n",
       " 'google:models/gemini-2.0-flash-lite-preview',\n",
       " 'google:models/gemini-2.0-pro-exp',\n",
       " 'google:models/gemini-2.0-pro-exp-02-05',\n",
       " 'google:models/gemini-exp-1206',\n",
       " 'google:models/gemini-2.0-flash-thinking-exp-01-21',\n",
       " 'google:models/gemini-2.0-flash-thinking-exp',\n",
       " 'google:models/gemini-2.0-flash-thinking-exp-1219',\n",
       " 'google:models/learnlm-1.5-pro-experimental',\n",
       " 'google:models/gemma-3-27b-it']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_registry.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register an OpenAI text-embedding model\n",
    "openai_info = ModelInfo(\n",
    "    id=\"openai:text-embedding-3-large\",\n",
    "    name=\"text-embedding-3-large\",\n",
    "    cost=ModelCost(input_cost_per_thousand=0.03, output_cost_per_thousand=0.06),\n",
    "    rate_limit=RateLimit(tokens_per_minute=80000, requests_per_minute=5000),\n",
    "    provider=ProviderInfo(name=\"OpenAI\", default_api_key=openai_key),\n",
    "    api_key=openai_key,\n",
    ")\n",
    "model_registry.register_model(openai_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try model registry\n",
    "taken from `src/ember/core/registry/model/examples/example.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ids: List[str] = [\n",
    "            \"openai:o1\",\n",
    "            \"openai:gpt-4o\",\n",
    "            \"openai:gpt-4o-mini\",\n",
    "            # \"anthropic:claude-3.5-sonnet\", # API key not working\n",
    "            # \"invalid:model\",  # Expected to trigger an error.\n",
    "            # \"google:model/gemini-1.5-pro\", # need to fix model alignment\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_id in model_ids:\n",
    "    try:\n",
    "        print(f\"➡️ Testing model: {model_id}\")\n",
    "\n",
    "        # Two usage styles are demonstrated below:\n",
    "        # 1. Service-based invocation: Recommended for automatic usage tracking.\n",
    "        service_response: ChatResponse = llm.invoke_model(\n",
    "            model_id=model_id,\n",
    "            prompt=\"Explain quantum computing in 50 words\",\n",
    "        )\n",
    "        print(f\"🛎️ Service response from {model_id}:\\n{service_response.data}\\n\")\n",
    "\n",
    "        # 2. Direct model instance usage: Useful for more granular or PyTorch-like workflows.\n",
    "        model = load_model(model_id=model_id, registry=model_registry)\n",
    "        direct_response: ChatResponse = model(\n",
    "            prompt=\"What's the capital of France?\"\n",
    "        )\n",
    "        print(f\"🎯 Direct response from {model_id}:\\n{direct_response.data}\\n\")\n",
    "\n",
    "    except Exception as error:\n",
    "        print(f\"❌ Error with model {model_id}: {str(error)}\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm(prompt=\"Hello!\", model_id=\"openai:gpt-4o\")\n",
    "print(response.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Neural Similarity Scoring - Cosine Similarity (WIP)\n",
    "\n",
    "- from `src/ember/core/utils/embedding_utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "# 1) Embedding Model Interfaces & Implementations\n",
    "################################################################\n",
    "\n",
    "\n",
    "class EmbeddingModel(Protocol):\n",
    "    \"\"\"Interface for embedding models.\n",
    "\n",
    "    This protocol defines the minimal interface required to compute a text\n",
    "    embedding. Implementations may use local models, external APIs, or custom\n",
    "    neural networks.\n",
    "\n",
    "    Methods:\n",
    "        embed_text: Compute the embedding for a given text.\n",
    "    \"\"\"\n",
    "\n",
    "    def embed_text(self, text: str) -> List[float]:\n",
    "        \"\"\"Computes the embedding vector for the provided text.\n",
    "\n",
    "        Args:\n",
    "            text (str): The text to be embedded.\n",
    "\n",
    "        Returns:\n",
    "            List[float]: A list of floats representing the embedding vector.\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "class Text_Embedding_Ada_002_Model:\n",
    "    \"\"\"Interface for embedding models.\n",
    "\n",
    "    This protocol defines the minimal interface required to compute a text\n",
    "    embedding. Implementations may use local models, external APIs, or custom\n",
    "    neural networks.\n",
    "\n",
    "    Methods:\n",
    "        embed_text: Compute the embedding for a given text.\n",
    "    \"\"\"\n",
    "\n",
    "    def embed_text(self, text: str) -> List[float]:\n",
    "        \"\"\"Computes the embedding vector for the provided text.\n",
    "\n",
    "        Args:\n",
    "            text (str): The text to be embedded.\n",
    "\n",
    "        Returns:\n",
    "            List[float]: A list of floats representing the embedding vector.\n",
    "        \"\"\"\n",
    "        response = llm(model_id=\"openai:text-embedding-ada-002\", prompt=text)\n",
    "        return response.embedding\n",
    "\n",
    "class Text_Embedding_3_EmbeddingModel(Protocol):\n",
    "    \"\"\"Interface for embedding models.\n",
    "\n",
    "    This protocol defines the minimal interface required to compute a text\n",
    "    embedding. Implementations may use local models, external APIs, or custom\n",
    "    neural networks.\n",
    "\n",
    "    Methods:\n",
    "        embed_text: Compute the embedding for a given text.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str = None):\n",
    "        \"\"\"Initializes the embedding model with the OpenAI API key.\n",
    "\n",
    "        Args:\n",
    "            api_key (str): OpenAI API key for authentication.\n",
    "        \"\"\"\n",
    "        self.api_key = api_key or os.environ.get(\"OPENAI_API_KEY\")\n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"OpenAI API key must be provided or set in the environment variable OPENAI_API_KEY.\")\n",
    "        openai.api_key = self.api_key\n",
    "\n",
    "    def embed_text(self, text: str) -> List[float]:\n",
    "        \"\"\"Computes the embedding vector for the provided text.\n",
    "\n",
    "        Args:\n",
    "            text (str): The text to be embedded.\n",
    "\n",
    "        Returns:\n",
    "            List[float]: A list of floats representing the embedding vector.\n",
    "        \"\"\"\n",
    "        response = openai.Embedding.create(\n",
    "            model=\"text-embedding-3\",\n",
    "            input=text\n",
    "        )\n",
    "        return response[\"data\"][0][\"embedding\"]\n",
    "\n",
    "\n",
    "class MockEmbeddingModel:\n",
    "    \"\"\"Mock implementation of an embedding model using naive ASCII encoding.\n",
    "\n",
    "    This simple model converts each character in the text to a normalized ASCII\n",
    "    value. It is intended solely for demonstration and testing purposes.\n",
    "\n",
    "    Methods:\n",
    "        embed_text: Converts text to a sequence of normalized ASCII values.\n",
    "    \"\"\"\n",
    "\n",
    "    def embed_text(self, text: str) -> List[float]:\n",
    "        \"\"\"Embeds text by converting each character to its normalized ASCII code.\n",
    "\n",
    "        Args:\n",
    "            text (str): The input text to be embedded.\n",
    "\n",
    "        Returns:\n",
    "            List[float]: A list of floats representing the embedding. Returns an\n",
    "            empty list if the text is empty.\n",
    "        \"\"\"\n",
    "        if not text:\n",
    "            return []\n",
    "        return [ord(ch) / 256.0 for ch in text]\n",
    "\n",
    "\n",
    "################################################################\n",
    "# 2) Similarity Metric Interface & Implementations\n",
    "################################################################\n",
    "\n",
    "\n",
    "class SimilarityMetric(ABC):\n",
    "    \"\"\"Abstract base class for computing similarity between embedding vectors.\n",
    "\n",
    "    Subclasses must implement the similarity method to calculate a similarity\n",
    "    score between two vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def similarity(self, vec_a: List[float], vec_b: List[float]) -> float:\n",
    "        \"\"\"Calculates the similarity between two embedding vectors.\n",
    "\n",
    "        Args:\n",
    "            vec_a (List[float]): The first embedding vector.\n",
    "            vec_b (List[float]): The second embedding vector.\n",
    "\n",
    "        Returns:\n",
    "            float: The similarity score, typically in the range [0, 1] or [-1, 1].\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "\n",
    "class CosineSimilarity(SimilarityMetric):\n",
    "    \"\"\"Implementation of cosine similarity for embedding vectors.\n",
    "\n",
    "    The cosine similarity is defined as:\n",
    "        similarity(a, b) = (a · b) / (||a|| * ||b||)\n",
    "\n",
    "    Returns 0.0 if either vector is empty or if any vector's norm is zero.\n",
    "    \"\"\"\n",
    "\n",
    "    def similarity(self, vec_a: List[float], vec_b: List[float]) -> float:\n",
    "        \"\"\"Computes cosine similarity between two embedding vectors.\n",
    "\n",
    "        Args:\n",
    "            vec_a (List[float]): The first embedding vector.\n",
    "            vec_b (List[float]): The second embedding vector.\n",
    "\n",
    "        Returns:\n",
    "            float: The cosine similarity score.\n",
    "        \"\"\"\n",
    "        if not vec_a or not vec_b:\n",
    "            return 0.0\n",
    "\n",
    "        dot_product: float = sum(a * b for a, b in zip(vec_a, vec_b))\n",
    "        norm_a: float = math.sqrt(sum(a * a for a in vec_a))\n",
    "        norm_b: float = math.sqrt(sum(b * b for b in vec_b))\n",
    "        if norm_a == 0 or norm_b == 0:\n",
    "            return 0.0\n",
    "\n",
    "        return dot_product / (norm_a * norm_b)\n",
    "\n",
    "\n",
    "################################################################\n",
    "# 3) High-Level Utility Function\n",
    "################################################################\n",
    "\n",
    "\n",
    "def calculate_text_similarity(\n",
    "    text1: str, text2: str, model: EmbeddingModel, metric: SimilarityMetric\n",
    ") -> float:\n",
    "    \"\"\"Calculates text similarity using an embedding model and a similarity metric.\n",
    "\n",
    "    This function generates embeddings for the provided texts and then computes a\n",
    "    similarity score using the given similarity metric.\n",
    "\n",
    "    Args:\n",
    "        text1 (str): The first text string.\n",
    "        text2 (str): The second text string.\n",
    "        model (EmbeddingModel): An instance conforming to the embedding model interface.\n",
    "        metric (SimilarityMetric): An instance implementing a similarity metric.\n",
    "\n",
    "    Returns:\n",
    "        float: The computed similarity score.\n",
    "    \"\"\"\n",
    "    embedding1: List[float] = model.embed_text(text=text1)\n",
    "    embedding2: List[float] = model.embed_text(text=text2)\n",
    "    return metric.similarity(vec_a=embedding1, vec_b=embedding2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'Hello world!' and 'Hello, world??': 0.9150491464734943\n"
     ]
    }
   ],
   "source": [
    "embedding_model: Text_Embedding_Ada_002_Model = Text_Embedding_Ada_002_Model()\n",
    "cosine: CosineSimilarity = CosineSimilarity()\n",
    "\n",
    "text_a: str = \"Hello world!\"\n",
    "text_b: str = \"Hello, world??\"\n",
    "\n",
    "diverse_text = [\"Bananas don't belong in briefcases\", \"Abraham Lincoln\", \"ERROR 404: Index Not Found\"]\n",
    "\n",
    "different_words_not_diverse_strs = [\"peanut butter and jelly\", \"bacon lettuce tomato\"]\n",
    "\n",
    "repetition_strs = [\"This is a sample text with lots of repetition.\", \n",
    "                \"This is a sample text with lots of repetition.\"]\n",
    "\n",
    "test_strings = [diverse_text, different_words_not_diverse_strs, repetition_strs]\n",
    "\n",
    "for test in test_strings:\n",
    "    score: float = calculate_text_similarity(\n",
    "        text1=test[0], text2=test[1], model=embedding_model, metric=cosine\n",
    "    )\n",
    "\n",
    "    print(f\"Cosine similarity Score: {score:.4f}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compression Ratio\n",
    "\n",
    "from `src/ember/core/utils/eval/evaluators.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_out = TypeVar(\"T_out\")\n",
    "T_truth = TypeVar(\"T_truth\")\n",
    "\n",
    "class ComposedEvaluator(IEvaluator[T_out, T_truth], Generic[T_out, T_truth]):\n",
    "    \"\"\"Combines an output extractor with an evaluator for the extracted data.\n",
    "\n",
    "    This evaluator first transforms the system output using the provided extractor,\n",
    "    then evaluates the extracted value using the specified base evaluator.\n",
    "\n",
    "    Args:\n",
    "        extractor: An object with an `extract` method to process the system output.\n",
    "        base_evaluator (IEvaluator): An evaluator that processes the extracted output.\n",
    "\n",
    "    Returns:\n",
    "        EvaluationResult: The result of the evaluation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        extractor: Any,  # Expecting an extractor with an `extract` method.\n",
    "        base_evaluator: IEvaluator[Any, Any],\n",
    "    ) -> None:\n",
    "        self.extractor = extractor\n",
    "        self.base_evaluator = base_evaluator\n",
    "\n",
    "    def evaluate(\n",
    "        self, system_output: T_out, correct_answer: Any, **kwargs: Any\n",
    "    ) -> EvaluationResult:\n",
    "        \"\"\"Evaluates the provided system output against the correct answer.\n",
    "\n",
    "        Args:\n",
    "            system_output (T_out): The raw output generated by the system.\n",
    "            correct_answer (Any): The expected correct answer.\n",
    "            **kwargs: Additional keyword arguments for extraction or evaluation.\n",
    "\n",
    "        Returns:\n",
    "            EvaluationResult: The result of evaluating the extracted value.\n",
    "        \"\"\"\n",
    "        extracted_value = self.extractor.extract(system_output, **kwargs)\n",
    "        return self.base_evaluator.evaluate(extracted_value, correct_answer, **kwargs)\n",
    "\n",
    "\n",
    "# Basic Evaluators\n",
    "\n",
    "\n",
    "class ExactMatchEvaluator(IEvaluator[str, str]):\n",
    "    \"\"\"Evaluator to check for an exact match between two strings,\n",
    "    ignoring differences in whitespace and case.\n",
    "\n",
    "    Example:\n",
    "        evaluator = ExactMatchEvaluator()\n",
    "        result = evaluator.evaluate(\"Hello World\", \"hello   world\")\n",
    "\n",
    "    Args:\n",
    "        compare_fn (Optional[Callable[[str, str], bool]]): Optional custom comparison function.\n",
    "            If not provided, strings are normalized (whitespace removed, lowercase) before comparison.\n",
    "\n",
    "    Returns:\n",
    "        EvaluationResult: The result containing a correctness flag and a score.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, compare_fn: Optional[Callable[[str, str], bool]] = None) -> None:\n",
    "        self.compare_fn = compare_fn or self._default_compare\n",
    "\n",
    "    def _default_compare(self, str1: str, str2: str) -> bool:\n",
    "        \"\"\"Default string comparison function that ignores case and whitespace.\n",
    "\n",
    "        Args:\n",
    "            str1 (str): First string to compare\n",
    "            str2 (str): Second string to compare\n",
    "\n",
    "        Returns:\n",
    "            bool: True if strings match after normalization\n",
    "        \"\"\"\n",
    "        return str1.strip().lower() == str2.strip().lower()\n",
    "\n",
    "    def evaluate(\n",
    "        self, system_output: str, correct_answer: str, **kwargs: Any\n",
    "    ) -> EvaluationResult:\n",
    "        \"\"\"Evaluates whether a system output exactly matches the correct answer.\n",
    "\n",
    "        Args:\n",
    "            system_output (str): The system-generated string.\n",
    "            correct_answer (str): The expected answer string.\n",
    "            **kwargs: Additional keyword arguments (unused).\n",
    "\n",
    "        Returns:\n",
    "            EvaluationResult: An object with `is_correct` set to True if the normalized strings match,\n",
    "                              along with a corresponding score.\n",
    "        \"\"\"\n",
    "        is_correct = self.compare_fn(system_output, correct_answer)\n",
    "        score = 1.0 if is_correct else 0.0\n",
    "        return EvaluationResult(is_correct=is_correct, score=score)\n",
    "\n",
    "class DiversityCompressionEvaluator(IEvaluator[List[str], None]):\n",
    "    \"\"\"\n",
    "    Evaluator to test ensemble outputs -> score them (float)\n",
    "    \"\"\"\n",
    "    def evaluate(\n",
    "            self, \n",
    "            system_output: List[str], \n",
    "            **kwargs) -> EvaluationResult:\n",
    "        if system_output is None or len(system_output) == 0:\n",
    "            return EvaluationResult(is_correct=False, score=-1)\n",
    "\n",
    "        # current compression ratio formula\n",
    "        # TODO: update scoring function to make it better\n",
    "        # -> like use token count\n",
    "\n",
    "        # example I was thinking about:\n",
    "        letter_sum = sum(len(response) for response in system_output)\n",
    "        ratio = 1/compression_ratio(system_output) * min(1, len(system_output)/5) * min(1, letter_sum/100)\n",
    "        # ratio = compression_ratio(system_output, algorithm='gzip',verbose=True)\n",
    "        return EvaluationResult(is_correct=True,score=ratio,metadata = {'responses': system_output})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_evaluator = DiversityCompressionEvaluator()\n",
    "\n",
    "# input_strs = [\n",
    "#     \";lkjawefopajwiefpoij23jf9aj8sdfj8903jf908j -- Understanding the importance of effective communication in the workplace cannot be overstated. Clear communication fosters a positive environment where people can express their ideas and work together efficiently. When team members understand one another, they can collaborate seamlessly, avoid misunderstandings, and achieve collective goals. Furthermore, communication skills are essential for building trust, resolving conflicts, and ensuring that expectations are clear. Whether through verbal discussions, emails, or presentations, knowing how to convey thoughts in an understandable way is key to success in any professional setting.\",\n",
    "#     \"fej89qw098efjq29f38j0938j20f398jqwe098fjq98wf -- In any workplace, the ability to communicate effectively is crucial for success. When individuals can clearly articulate their ideas and listen actively, it leads to a more productive and harmonious environment. Good communication prevents misunderstandings, aids in team collaboration, and helps in meeting shared objectives. It also plays a vital role in fostering trust among colleagues, resolving disputes, and ensuring transparency. Whether it’s through face-to-face conversations, written messages, or virtual meetings, mastering communication is essential to creating a positive, high-functioning work culture.\",\n",
    "#     \"Effective communication is a cornerstone of a successful work environment. When employees communicate clearly and efficiently, it improves the overall flow of work and enhances collaboration. Clear exchanges of ideas help to eliminate confusion, build mutual trust, and ensure that everyone is aligned in their goals. Additionally, strong communication skills are key to managing conflicts and setting clear expectations among teams. Whether in meetings, emails, or other formats, being able to communicate effectively contributes to a thriving and efficient workplace.\",\n",
    "#     \"The role of communication in the workplace cannot be overlooked. It serves as the foundation for successful teamwork and organizational growth. When team members share information clearly, it promotes a collaborative atmosphere and reduces the risk of errors or misinterpretations. Strong communication is also vital in building relationships, resolving issues, and making sure everyone is on the same page. Whether it's verbal exchanges or written correspondence, honing your ability to communicate well is vital for fostering an effective work environment.\",\n",
    "#     \"Communication within the workplace is a vital element for success. Clear and open communication promotes a cooperative and efficient atmosphere, helping team members to better understand each other’s ideas and work toward common goals. It reduces confusion, builds trust, and allows for smoother problem-solving when conflicts arise. By conveying thoughts and expectations effectively, individuals can create stronger working relationships and a productive team dynamic. Whether through emails, phone calls, or face-to-face interactions, mastering communication techniques is key for professional achievement.\",\n",
    "# ]\n",
    "\n",
    "input_strs = [\"hi there\", \"hi\", \"hello\", \"yo whatup\"]\n",
    "\n",
    "# input_strs = [\"This is a sample text with lots of repetition.\", \n",
    "#                 \"This is a sample text with lots of repetition.\",\n",
    "#                 \"This is a sample text with lots of repetition.\"]\n",
    "\n",
    "edit_distance = compression_evaluator.evaluate(input_strs)\n",
    "\n",
    "print(f\"Compression Score: {edit_distance.score:.4f}\")\n",
    "print(f\"Is Correct: {edit_distance.is_correct}\")\n",
    "print(f\"Metadata: {edit_distance.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EvaluationResult:\n",
    "    is_correct: bool\n",
    "    score: float\n",
    "    metadata: dict\n",
    "\n",
    "class DiversityEditDistanceEvaluator:\n",
    "\n",
    "    def evaluate(self, system_output: List[str], **kwargs) -> EvaluationResult:\n",
    "        if system_output is None or len(system_output) == 0:\n",
    "            return EvaluationResult(is_correct=False, score=-1, metadata={})\n",
    "\n",
    "        diversity_score = self.compute_distance(system_output)\n",
    "\n",
    "        return EvaluationResult(\n",
    "            is_correct=True, \n",
    "            score=diversity_score,\n",
    "            metadata={'responses': system_output}\n",
    "        )\n",
    "\n",
    "    def compute_distance(self, outputs: List[str]) -> float:\n",
    "        n = len(outputs)\n",
    "        if n < 2:\n",
    "            return 0.0\n",
    "\n",
    "        total_distance = 0\n",
    "        pairs = 0\n",
    "\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n):\n",
    "                dist = Levenshtein.distance(outputs[i], outputs[j])\n",
    "                max_len = max(len(outputs[i]), len(outputs[j]))\n",
    "                normalized_dist = dist / max_len if max_len > 0 else 0 \n",
    "                total_distance += normalized_dist\n",
    "                pairs += 1\n",
    "        \n",
    "        return total_distance / pairs if pairs > 0 else 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diversity Score: 0.8301\n",
      "Is Correct: True\n",
      "Metadata: {'responses': ['hi there', 'hi', 'hello', 'yo whatup']}\n"
     ]
    }
   ],
   "source": [
    "distance_evaluator = DiversityEditDistanceEvaluator()\n",
    "\n",
    "# input_strs = [\n",
    "#     \";lkjawefopajwiefpoij23jf9aj8sdfj8903jf908j -- Understanding the importance of effective communication in the workplace cannot be overstated. Clear communication fosters a positive environment where people can express their ideas and work together efficiently. When team members understand one another, they can collaborate seamlessly, avoid misunderstandings, and achieve collective goals. Furthermore, communication skills are essential for building trust, resolving conflicts, and ensuring that expectations are clear. Whether through verbal discussions, emails, or presentations, knowing how to convey thoughts in an understandable way is key to success in any professional setting.\",\n",
    "#     \"fej89qw098efjq29f38j0938j20f398jqwe098fjq98wf -- In any workplace, the ability to communicate effectively is crucial for success. When individuals can clearly articulate their ideas and listen actively, it leads to a more productive and harmonious environment. Good communication prevents misunderstandings, aids in team collaboration, and helps in meeting shared objectives. It also plays a vital role in fostering trust among colleagues, resolving disputes, and ensuring transparency. Whether it’s through face-to-face conversations, written messages, or virtual meetings, mastering communication is essential to creating a positive, high-functioning work culture.\",\n",
    "#     \"Effective communication is a cornerstone of a successful work environment. When employees communicate clearly and efficiently, it improves the overall flow of work and enhances collaboration. Clear exchanges of ideas help to eliminate confusion, build mutual trust, and ensure that everyone is aligned in their goals. Additionally, strong communication skills are key to managing conflicts and setting clear expectations among teams. Whether in meetings, emails, or other formats, being able to communicate effectively contributes to a thriving and efficient workplace.\",\n",
    "#     \"The role of communication in the workplace cannot be overlooked. It serves as the foundation for successful teamwork and organizational growth. When team members share information clearly, it promotes a collaborative atmosphere and reduces the risk of errors or misinterpretations. Strong communication is also vital in building relationships, resolving issues, and making sure everyone is on the same page. Whether it's verbal exchanges or written correspondence, honing your ability to communicate well is vital for fostering an effective work environment.\",\n",
    "#     \"Communication within the workplace is a vital element for success. Clear and open communication promotes a cooperative and efficient atmosphere, helping team members to better understand each other’s ideas and work toward common goals. It reduces confusion, builds trust, and allows for smoother problem-solving when conflicts arise. By conveying thoughts and expectations effectively, individuals can create stronger working relationships and a productive team dynamic. Whether through emails, phone calls, or face-to-face interactions, mastering communication techniques is key for professional achievement.\",\n",
    "# ]\n",
    "\n",
    "input_strs = [\"hi there\", \"hi\", \"hello\", \"yo whatup\"]\n",
    "\n",
    "# input_strs = [\"This is a sample text with lots of repetition.\", \n",
    "#                 \"This is a sample text with lots of repetition.\",\n",
    "#                 \"This is a sample text with lots of repetition.\"]\n",
    "\n",
    "edit_distance = distance_evaluator.evaluate(input_strs)\n",
    "\n",
    "print(f\"Edit Distance Score: {edit_distance.score:.4f}\")\n",
    "print(f\"Is Correct: {edit_distance.is_correct}\")\n",
    "print(f\"Metadata: {edit_distance.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Novelty Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EvaluationResult:\n",
    "    is_correct: bool\n",
    "    score: float\n",
    "    metadata: dict\n",
    "\n",
    "class DiversityNoveltyEvaluator:\n",
    "    \n",
    "    def evaluate(self, model: EmbeddingModel, system_output: List[str], **kwargs) -> EvaluationResult:\n",
    "        if not system_output or len(system_output) == 0:\n",
    "            return EvaluationResult(is_correct=False, score=-1, metadata={})\n",
    "\n",
    "        novelty_scores = [self.compute_novelty(r, system_output[:i]) for i, r in enumerate(system_output)]\n",
    "\n",
    "        avg_novelty = sum(novelty_scores) / len(novelty_scores) if novelty_scores else 0.0\n",
    "\n",
    "        return EvaluationResult(\n",
    "            is_correct=True,\n",
    "            score=avg_novelty,\n",
    "            metadata={'responses': system_output, 'novelty_scores': novelty_scores}\n",
    "        )\n",
    "\n",
    "    def compute_novelty(self, response: str, prior_responses: List[str]) -> float:\n",
    "        if not prior_responses:\n",
    "            return 1.0\n",
    "\n",
    "        new_embedding = self.model.embed_text(response)\n",
    "        prior_embeddings = [self.model.embed_text(r) for r in prior_responses]\n",
    "\n",
    "        similarities = [\n",
    "            np.dot(new_embedding, prior_embedding) /\n",
    "            (np.linalg.norm(new_embedding) * np.linalg.norm(prior_embedding))\n",
    "            for prior_embedding in prior_embeddings\n",
    "        ]\n",
    "\n",
    "        return 1 - max(similarities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluationResult(is_correct=True, score=0.08368770360509659, metadata={'responses': ['Hello world!', 'Hi there!', 'Goodbye!']})\n"
     ]
    }
   ],
   "source": [
    "novelty_evaluator = DiversityNoveltyEvaluator()\n",
    "\n",
    "input_strs = [\"hi there\", \"hi\", \"hello\", \"yo whatup\"]\n",
    "\n",
    "mock_model: MockEmbeddingModel = MockEmbeddingModel()\n",
    "novelty = novelty_evaluator.evaluate(mock_model, input_strs)\n",
    "\n",
    "print(f\"Novelty Score: {novelty.score:.4f}\")\n",
    "print(f\"Is Correct: {novelty.is_correct}\")\n",
    "print(f\"Metadata: {novelty.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to combine all the scores (cosine similarity, compression ratio, edit distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_model: MockEmbeddingModel = MockEmbeddingModel()\n",
    "cosine: CosineSimilarity = CosineSimilarity()\n",
    "exact_evaluator = ExactMatchEvaluator()\n",
    "compression_evaluator = DiversityCompressionEvaluator()\n",
    "edit_dist_evaluator = DiversityEditDistanceEvaluator()\n",
    "\n",
    "def ensemble_diversity(strings):\n",
    "    compression = compression_evaluator.evaluate(strings)\n",
    "    # print(\"compression (1/compression == compression/original) result:\", compression)\n",
    "    cosine_scores = list()\n",
    "    for ind1 in range(len(strings)):\n",
    "        ind2 = ind1+1 if ind1+1 != len(strings) else 0\n",
    "        curr_score = calculate_text_similarity(text1=strings[ind1], text2=strings[ind2], model=mock_model, metric=cosine)\n",
    "        # print(f\"SimilarityScore between ind1={ind1} and ind2={ind2}: {curr_score}\")\n",
    "        cosine_scores.append(curr_score)\n",
    "    avg_cosine_score = np.average(cosine_scores)\n",
    "    # print(f\"Avg cosine similarity: {avg_score}\")\n",
    "    # print(f\"diversity cosine-sim inverse: {1-avg_score}\")\n",
    "    edit_distance = edit_dist_evaluator.evaluate(strings)\n",
    "    # print(f\"edit-dist score: {edit_distance.score:.4f}\")\n",
    "    # print(\"-------------------------------\")\n",
    "    diversity_score = ((1 - avg_cosine_score) + min(compression.score, 1) + edit_distance.score)/3\n",
    "    # print(f\"possible diversity score (higher is better): {diversity_score}\")\n",
    "    return diversity_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_strs = []\n",
    "scores = []\n",
    "input_strs.append([\"This is a sample text with lots of repetition.\", \n",
    "                \"This is a sample text with lots of repetition.\",\n",
    "                \"This is a sample text with lots of repetition.\"])\n",
    "\n",
    "responses = []\n",
    "for i in range(10):\n",
    "    res = llm(prompt=\"Tell me a funny joke. Keep it concise.\", model_id=\"openai:gpt-4o\").data.replace(\"\\n\", \"\")\n",
    "    responses.append(res)\n",
    "input_strs.append(responses)\n",
    "\n",
    "responses = []\n",
    "res = llm(prompt=\"Tell me 10 different jokes. make them split with \\'||\\'. Don't say anything else besides the joke. \", model_id=\"openai:gpt-4o\").data.replace(\"\\n\", \"\").split('||')\n",
    "responses += res\n",
    "input_strs.append(responses)\n",
    "\n",
    "# input_strs.append([\n",
    "#     \"Understanding the importance of effective communication in the workplace cannot be overstated. Clear communication fosters a positive environment where people can express their ideas and work together efficiently. When team members understand one another, they can collaborate seamlessly, avoid misunderstandings, and achieve collective goals. Furthermore, communication skills are essential for building trust, resolving conflicts, and ensuring that expectations are clear. Whether through verbal discussions, emails, or presentations, knowing how to convey thoughts in an understandable way is key to success in any professional setting.\",\n",
    "#     \"In any workplace, the ability to communicate effectively is crucial for success. When individuals can clearly articulate their ideas and listen actively, it leads to a more productive and harmonious environment. Good communication prevents misunderstandings, aids in team collaboration, and helps in meeting shared objectives. It also plays a vital role in fostering trust among colleagues, resolving disputes, and ensuring transparency. Whether it’s through face-to-face conversations, written messages, or virtual meetings, mastering communication is essential to creating a positive, high-functioning work culture.\",\n",
    "#     \"Effective communication is a cornerstone of a successful work environment. When employees communicate clearly and efficiently, it improves the overall flow of work and enhances collaboration. Clear exchanges of ideas help to eliminate confusion, build mutual trust, and ensure that everyone is aligned in their goals. Additionally, strong communication skills are key to managing conflicts and setting clear expectations among teams. Whether in meetings, emails, or other formats, being able to communicate effectively contributes to a thriving and efficient workplace.\",\n",
    "#     \"The role of communication in the workplace cannot be overlooked. It serves as the foundation for successful teamwork and organizational growth. When team members share information clearly, it promotes a collaborative atmosphere and reduces the risk of errors or misinterpretations. Strong communication is also vital in building relationships, resolving issues, and making sure everyone is on the same page. Whether it's verbal exchanges or written correspondence, honing your ability to communicate well is vital for fostering an effective work environment.\",\n",
    "#     \"Communication within the workplace is a vital element for success. Clear and open communication promotes a cooperative and efficient atmosphere, helping team members to better understand each other’s ideas and work toward common goals. It reduces confusion, builds trust, and allows for smoother problem-solving when conflicts arise. By conveying thoughts and expectations effectively, individuals can create stronger working relationships and a productive team dynamic. Whether through emails, phone calls, or face-to-face interactions, mastering communication techniques is key for professional achievement.\",\n",
    "# ])\n",
    "\n",
    "responses = []\n",
    "res1 = llm(prompt=\"Tell me a story about how quantum computers work. Make it 100 words. Don't say anything else besides the story. \", model_id=\"openai:gpt-4o\").data\n",
    "responses.append(res1)\n",
    "res2 = llm(prompt=\"Tell me a story about bunnies frolicking in the grass. Make it 100 words. Don't say anything else besides the story. \", model_id=\"openai:gpt-4o\").data\n",
    "responses.append(res2)\n",
    "res3 = llm(prompt=\"Tell me a story about the pokemon pikachu and it's adventures. Make it 100 words. Don't say anything else besides the story. \", model_id=\"openai:gpt-4o\").data\n",
    "responses.append(res3)\n",
    "res4 = llm(prompt=\"Tell me a story about a ramen shop. Make it 100 words. Don't say anything else besides the story. \", model_id=\"openai:gpt-4o\").data\n",
    "responses.append(res4)\n",
    "input_strs.append(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(input_strs)):\n",
    "    print(f\"{i} -------------------\")\n",
    "    for s in input_strs[i]:\n",
    "        print(\"\\t- \" + s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [ensemble_diversity(s_arr) for s_arr in input_strs]\n",
    "labels = [str(number) for number in range(1, len(input_strs) + 1)]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(labels, scores)\n",
    "plt.xlabel(\"Response\")\n",
    "plt.ylabel(\"Diversity Score\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Potential other cases to explore\n",
    "- work ensembling all \"diversity\" related metrics \n",
    "  - add more metrics\n",
    "  - tune added metrics\n",
    "- combination of validation/hallucination metric + ensembled diversity metric -> score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ember_upgrade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
