{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb8b2ff3-710f-400e-a7b4-5c62bc2f8d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "# 1) Import our dataset registry tools:\n",
    "from src.ember.registry.dataset.registry.metadata_registry import (\n",
    "    DatasetMetadataRegistry,\n",
    ")\n",
    "from src.ember.registry.dataset.registry.loader_factory import DatasetLoaderFactory\n",
    "from src.ember.registry.dataset.registry.initialization import (\n",
    "    initialize_dataset_registry,\n",
    ")\n",
    "\n",
    "# 2) Import or define dataset loader/validator/sampler:\n",
    "# If you have existing ones, import them. For now, we'll assume defaults or mocks.\n",
    "from src.ember.registry.dataset.base.loaders import (\n",
    "    HuggingFaceDatasetLoader,\n",
    "    IDatasetLoader,\n",
    ")\n",
    "from src.ember.registry.dataset.base.validators import IDatasetValidator\n",
    "from src.ember.registry.dataset.base.samplers import IDatasetSampler\n",
    "from src.ember.registry.dataset.base.models import DatasetInfo, DatasetEntry, TaskType\n",
    "from src.ember.registry.dataset.base.preppers import IDatasetPrepper\n",
    "from src.ember.registry.dataset.datasets.mmlu import MMLUConfig\n",
    "from src.ember.registry.dataset.base.validators import DatasetValidator\n",
    "from src.ember.registry.dataset.base.samplers import DatasetSampler\n",
    "from src.ember.registry.dataset.datasets.halueval import HaluEvalConfig\n",
    "\n",
    "# 3) Import the DatasetService to actually use the pipeline:\n",
    "from src.ember.registry.dataset.registry.service import DatasetService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22ef07e3-857c-44cf-b4f5-a0ab1752249a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d553c03-57f2-4481-b347-9d162e9e96ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Create a metadata registry and loader factory:\n",
    "metadata_registry = DatasetMetadataRegistry()\n",
    "loader_factory = DatasetLoaderFactory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f392f48-2d84-42f1-8035-bcb3beb75059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Initialize the registry with known “built-in” datasets:\n",
    "initialize_dataset_registry(metadata_registry, loader_factory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1339a867-eac7-450d-a777-d223431a6984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Optionally, discover any additional plugin-based preppers from pyproject.toml:\n",
    "loader_factory.discover_and_register_plugins()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a336c3c6-66bc-47b6-a3e3-9c1732fd64d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Retrieve dataset info from our registry (for example, \"mmlu\"):\n",
    "mmlu_info: Optional[DatasetInfo] = metadata_registry.get(\"mmlu\")\n",
    "if not mmlu_info:\n",
    "    raise ValueError(\"MMLU dataset not properly registered.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1560338f-2f74-44c4-ae0e-6370f3e2547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Obtain a prepper class from loader_factory:\n",
    "#    This is the class that knows how to format MMLU data into DatasetEntry objects.\n",
    "mmlu_prepper_class = loader_factory.get_prepper_class(\"mmlu\")\n",
    "if not mmlu_prepper_class:\n",
    "    raise ValueError(\"No MMLU prepper found. Make sure it's registered.\")\n",
    "\n",
    "# 5a) Create an MMLUConfig specifying which sub-config and split you want:\n",
    "mmlu_config = MMLUConfig(config_name=\"abstract_algebra\", split=\"dev\")\n",
    "\n",
    "# 5b) Pass it into the MMLUPrepper constructor:\n",
    "mmlu_prepper: IDatasetPrepper = mmlu_prepper_class(config=mmlu_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6805fe2-79fd-4fb2-95ff-3cf5b4783347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Construct a dataset loader, validator, and sampler:\n",
    "#    (Replace HuggingFaceDatasetLoader with your real loader if you have a custom approach.)\n",
    "loader: IDatasetLoader = HuggingFaceDatasetLoader()\n",
    "validator: IDatasetValidator = DatasetValidator()\n",
    "sampler: IDatasetSampler = DatasetSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42e4850b-2ead-4c6c-8fbf-6b8eb3bbab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Instantiate a DatasetService to handle load, validation, transform, sampling, and prep:\n",
    "dataset_service = DatasetService(\n",
    "    loader=loader,\n",
    "    validator=validator,\n",
    "    sampler=sampler,\n",
    "    transformers=[],  # Insert any specialized transformers if needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db2aa66-89c9-413d-b399-e121ccb29400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Load and prepare the dataset:\n",
    "#    \"mmlu\" is a Hugging Face dataset name in the code snippet, but you’d use a real ID.\n",
    "logger.info(f\"Loading and preparing dataset: {mmlu_info.name}\")\n",
    "try:\n",
    "    # Pass the full MMLUConfig object so both config_name and split are handled:\n",
    "    dataset_entries: List[DatasetEntry] = dataset_service.load_and_prepare(\n",
    "        dataset_info=mmlu_info, prepper=mmlu_prepper, config=mmlu_config, num_samples=5\n",
    "    )\n",
    "\n",
    "    # 9) Print or process these dataset entries:\n",
    "    logger.info(\n",
    "        f\"Received {len(dataset_entries)} prepared entries for '{mmlu_info.name}'.\"\n",
    "    )\n",
    "    for i, entry in enumerate(dataset_entries):\n",
    "        logger.info(f\"Entry #{i+1}:\\n{entry.model_dump_json(indent=2)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error during dataset preparation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db1f560-cbc5-4374-9a3d-49dc49b678d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Let's do the same for HaluEval:\n",
    "halu_info: Optional[DatasetInfo] = metadata_registry.get(\"halueval\")\n",
    "if not halu_info:\n",
    "    raise ValueError(\"HaluEval dataset not properly registered.\")\n",
    "\n",
    "halu_prepper_class = loader_factory.get_prepper_class(\"halueval\")\n",
    "if not halu_prepper_class:\n",
    "    raise ValueError(\"No HaluEval prepper found. Make sure it's registered.\")\n",
    "\n",
    "# Create config & prepper, defaulting to config_name=\"qa\", split=\"data\"\n",
    "halu_config = HaluEvalConfig()\n",
    "halu_prepper: IDatasetPrepper = halu_prepper_class(config=halu_config)\n",
    "\n",
    "logger.info(f\"Loading and preparing dataset: {halu_info.name}\")\n",
    "try:\n",
    "    halu_dataset_entries: List[DatasetEntry] = dataset_service.load_and_prepare(\n",
    "        dataset_info=halu_info, prepper=halu_prepper, config=halu_config, num_samples=3\n",
    "    )\n",
    "    logger.info(\n",
    "        f\"Received {len(halu_dataset_entries)} prepared entries for '{halu_info.name}'.\"\n",
    "    )\n",
    "    for i, entry in enumerate(halu_dataset_entries):\n",
    "        logger.info(f\"[HaluEval] Entry #{i+1}:\\n{entry.model_dump_json(indent=2)}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error during HaluEval dataset preparation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dea3b51-b7a4-4461-b39f-81b296951adc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
